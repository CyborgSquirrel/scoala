{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4337df0d-0e8b-48bf-8d2a-4617a639d59a",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9ed0b79f-52b9-4230-8dd5-b7273c86dce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import sklearn.linear_model\n",
    "import sklearn.preprocessing\n",
    "import sklearn.metrics\n",
    "import sklearn.datasets\n",
    "import numpy as np\n",
    "import dataclasses\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "import ipywidgets\n",
    "import typing\n",
    "import abc\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339ee2c4-f050-4c90-9626-c3ec53efaf46",
   "metadata": {},
   "source": [
    "# Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "049f0f61-2181-4e3d-87a9-f0e0b8077e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclasses.dataclass\n",
    "class HappinessData:\n",
    "    gdp: np.ndarray\n",
    "    freedom: np.ndarray\n",
    "    happiness: np.ndarray\n",
    "\n",
    "def read_happiness_data(path: str) -> HappinessData:\n",
    "    with open(path) as f:\n",
    "        reader = csv.reader(f)\n",
    "        header = next(reader)\n",
    "        \n",
    "        gdp_index = header.index(\"Economy..GDP.per.Capita.\")\n",
    "        freedom_index = header.index(\"Freedom\")\n",
    "        happiness_index = header.index(\"Happiness.Score\")\n",
    "        \n",
    "        gdp_values = []\n",
    "        freedom_values = []\n",
    "        happiness_values = []\n",
    "        \n",
    "        for row in reader:\n",
    "            gdp_values.append(float(row[gdp_index]))\n",
    "            freedom_values.append(float(row[freedom_index]))\n",
    "            happiness_values.append(float(row[happiness_index]))\n",
    "        \n",
    "        gdp_array = np.array(gdp_values)\n",
    "        freedom_array = np.array(freedom_values)\n",
    "        happiness_array = np.array(happiness_values)\n",
    "        \n",
    "        return HappinessData(\n",
    "            gdp_array,\n",
    "            freedom_array,\n",
    "            happiness_array,\n",
    "        )\n",
    "\n",
    "happiness_data = read_happiness_data(\"data/2017.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6748282-27d0-49c7-95ea-c495fd7bf6ae",
   "metadata": {},
   "source": [
    "# Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff478245-b912-484f-9a2c-21eb7027e7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scaler(metaclass=abc.ABCMeta):\n",
    "    @abc.abstractmethod\n",
    "    def fit(self, inp: np.ndarray):\n",
    "        pass\n",
    "    \n",
    "    @abc.abstractmethod\n",
    "    def transform(self, inp: np.ndarray) -> np.ndarray:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6f123e2-e24b-4273-86e7-b501d2dc4b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Regressor(metaclass=abc.ABCMeta):\n",
    "    @abc.abstractmethod\n",
    "    def fit(self, inp: np.ndarray, out: np.ndarray):\n",
    "        pass\n",
    "    \n",
    "    @abc.abstractmethod\n",
    "    def predict(self, inp: np.ndarray) -> np.ndarray:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8593f521-1043-4ffa-a9aa-041cb2accb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "length = len(happiness_data.happiness)\n",
    "\n",
    "inp_uni = happiness_data.gdp.reshape(length, 1)\n",
    "out_uni = happiness_data.happiness.reshape(length, 1)\n",
    "\n",
    "inp_multi = np.stack([happiness_data.gdp, happiness_data.freedom], 1)\n",
    "out_multi = happiness_data.happiness.reshape(length, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a032936c-148c-435e-a952-ac51cbfea1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "TScaler = typing.TypeVar(\"TScaler\", bound=Scaler)\n",
    "TRegressor = typing.TypeVar(\"TRegressor\", bound=Regressor)\n",
    "def train_and_test(\n",
    "    *,\n",
    "    inp: np.ndarray,\n",
    "    out: np.ndarray,\n",
    "    train_percent: float,\n",
    "    ScalerType: typing.Type[TScaler],\n",
    "    RegressorType: typing.Type[TRegressor],\n",
    "):\n",
    "    length = len(inp)\n",
    "\n",
    "    # shuffle data\n",
    "    indices = np.arange(length)\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    inp = inp[indices]\n",
    "    out = out[indices]\n",
    "\n",
    "    # split into train and test\n",
    "    inp_train = inp[:int(length*train_percent)]\n",
    "    out_train = out[:int(length*train_percent)]\n",
    "\n",
    "    inp_test = inp[int(length*train_percent):]\n",
    "    out_test = out[int(length*train_percent):]\n",
    "\n",
    "    # normallize\n",
    "    scaler = ScalerType()\n",
    "    scaler.fit(inp_train)\n",
    "    inp_train = scaler.transform(inp_train)\n",
    "    inp_test = scaler.transform(inp_test)\n",
    "\n",
    "    scaler = ScalerType()\n",
    "    scaler.fit(out_train)\n",
    "    out_train = scaler.transform(out_train).flatten()\n",
    "    out_test = scaler.transform(out_test).flatten()\n",
    "\n",
    "    # train\n",
    "    regressor = RegressorType()\n",
    "    regressor.fit(inp_train, out_train)\n",
    "\n",
    "    # test\n",
    "    predicted_test = regressor.predict(inp_test)\n",
    "    mse = sklearn.metrics.mean_squared_error(out_test, predicted_test)\n",
    "\n",
    "    print(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506b2cc1-3a63-467c-afcb-e345a97cc2fa",
   "metadata": {},
   "source": [
    "## Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05da7711-b3eb-49ef-bf66-c97ca784ca1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToolScaler(Scaler):\n",
    "    def __init__(self):\n",
    "        self.__scaler = sklearn.preprocessing.StandardScaler()\n",
    "    \n",
    "    def fit(self, inp: np.ndarray):\n",
    "        self.__scaler.fit(inp)\n",
    "    \n",
    "    def transform(self, inp: np.ndarray) -> np.ndarray:\n",
    "        out = self.__scaler.transform(inp)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0861ae8-6c22-4182-874e-5e73c3d2c789",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToolRegressor(Regressor):\n",
    "    def __init__(self):\n",
    "        self.__regressor = sklearn.linear_model.SGDRegressor()\n",
    "    \n",
    "    def fit(self, inp: np.ndarray, out: np.ndarray):\n",
    "        self.__regressor.fit(inp, out)\n",
    "    \n",
    "    def predict(self, inp: np.ndarray) -> np.ndarray:\n",
    "        out = self.__regressor.predict(inp)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0020d86c-9e37-4874-af9a-9d621ad4ce13",
   "metadata": {},
   "source": [
    "### Univariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ff4e41f1-a48d-4953-9dd3-5b7aab102396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41020560901400116\n"
     ]
    }
   ],
   "source": [
    "train_and_test(\n",
    "    inp=inp_uni,\n",
    "    out=out_uni,\n",
    "    train_percent=0.80,\n",
    "    ScalerType=ToolScaler,\n",
    "    RegressorType=ToolRegressor,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3a833b-327a-4308-bbbb-877ebbf850c4",
   "metadata": {},
   "source": [
    "### Multivariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6a371b5e-54ab-4473-a510-cf61fcaee09b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2282979105561317\n"
     ]
    }
   ],
   "source": [
    "train_and_test(\n",
    "    inp=inp_multi,\n",
    "    out=out_multi,\n",
    "    train_percent=0.80,\n",
    "    ScalerType=ToolScaler,\n",
    "    RegressorType=ToolRegressor,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206fda50-7980-43e4-a0a8-575286d28563",
   "metadata": {},
   "source": [
    "## Mine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4f32b19-3163-4d75-b523-60fb55700047",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_2d_shape(matrix: list[list[typing.Any]]) -> (int, int):\n",
    "    width = None\n",
    "    height = len(matrix)\n",
    "    for row in matrix:\n",
    "        if width is None:\n",
    "            width = len(row)\n",
    "        assert width == len(row)\n",
    "    return (width, height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb2c4cb0-cadb-4093-8bf1-057ca9680e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyScaler(Scaler):\n",
    "    def __init__(self):\n",
    "        self.__mean = None\n",
    "        self.__std = None\n",
    "    \n",
    "    def fit(self, inp: np.ndarray):\n",
    "        inp = inp.tolist()\n",
    "        inp_shape = get_2d_shape(inp)\n",
    "        self.__mean = [\n",
    "            sum(\n",
    "                inp[inp_row_index][inp_column_index]\n",
    "                for inp_row_index in range(inp_shape[1])\n",
    "            ) / inp_shape[1]\n",
    "            for inp_column_index in range(inp_shape[0])\n",
    "        ]\n",
    "        self.__std = [\n",
    "            math.sqrt(\n",
    "                sum(\n",
    "                    (inp[inp_row_index][inp_column_index] - mean)**2\n",
    "                    for inp_row_index in range(inp_shape[1])\n",
    "                ) / (inp_shape[1] - 1)\n",
    "            )\n",
    "            for mean, inp_column_index in zip(self.__mean, range(inp_shape[0]))\n",
    "        ]\n",
    "    \n",
    "    def transform(self, inp: np.ndarray) -> np.ndarray:\n",
    "        inp = inp.tolist()\n",
    "        inp_shape = get_2d_shape(inp)\n",
    "        \n",
    "        out = []\n",
    "        for row in inp:\n",
    "            new_row = []\n",
    "            out.append(new_row)\n",
    "            for mean, std, value in zip(self.__mean, self.__std, row):\n",
    "                new_row.append((value - mean) / std)\n",
    "        \n",
    "        return np.array(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a0fe9c9d-881e-4653-9fa4-b09276ea8809",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyRegressor(Regressor):\n",
    "    def __init__(self):\n",
    "        self.__learning_rate = 0.1\n",
    "        self.__w = None\n",
    "    \n",
    "    def fit(self, inp: np.ndarray, out: np.ndarray):\n",
    "        inp = inp.tolist()\n",
    "        out = out.tolist()\n",
    "        \n",
    "        inp_shape = get_2d_shape(inp)\n",
    "        w = [0] * (inp_shape[0] + 1)\n",
    "        \n",
    "        for iteration_index in range(1000):\n",
    "            gradient_sum = [0] * (inp_shape[0] + 1)\n",
    "            for inp_values, out_value in zip(inp, out):\n",
    "                out_computed = sum(\n",
    "                    inp_value * w_value\n",
    "                    for inp_value, w_value in zip([1] + inp_values, w)\n",
    "                )\n",
    "                err = out_computed - out_value\n",
    "                gradient_sum = [\n",
    "                    gradient_sum_value + err * inp_value\n",
    "                    for gradient_sum_value, inp_value in zip(gradient_sum, [0] + inp_values)\n",
    "                ]\n",
    "            \n",
    "            gradient_mean = [\n",
    "                gradient_sum_value / len(inp)\n",
    "                for gradient_sum_value in gradient_sum\n",
    "            ]\n",
    "            w_new = [\n",
    "                w_value - gradient_mean_value * self.__learning_rate\n",
    "                for w_value, gradient_mean_value in zip(w, gradient_mean)\n",
    "            ]\n",
    "            w = w_new\n",
    "        \n",
    "        self.__w = w\n",
    "    \n",
    "    def predict(self, inp: np.ndarray) -> np.ndarray:\n",
    "        inp = inp.tolist()\n",
    "        out = []\n",
    "        for inp_values in inp:\n",
    "            out_computed = sum(\n",
    "                inp_value * w_value\n",
    "                for inp_value, w_value in zip([1] + inp_values, self.__w)\n",
    "            )\n",
    "            out.append(out_computed)\n",
    "        return np.array(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5eb656-3b9f-4ce8-a2f7-5859c7d702f2",
   "metadata": {},
   "source": [
    "### Univariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "98059235-2e39-4161-8742-46f453cc8444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35599698162311666\n"
     ]
    }
   ],
   "source": [
    "train_and_test(\n",
    "    inp=inp_uni,\n",
    "    out=out_uni,\n",
    "    train_percent=0.80,\n",
    "    ScalerType=MyScaler,\n",
    "    RegressorType=MyRegressor,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd635848-fc34-44f4-8fab-2d3377e04af3",
   "metadata": {},
   "source": [
    "### Multivariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "2c4f8b99-a0e1-4f72-b724-d6880676c29b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1129134997649597\n"
     ]
    }
   ],
   "source": [
    "train_and_test(\n",
    "    inp=inp_multi,\n",
    "    out=out_multi,\n",
    "    train_percent=0.80,\n",
    "    ScalerType=MyScaler,\n",
    "    RegressorType=MyRegressor,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7539cd-2ad8-4eeb-954a-22383917c81b",
   "metadata": {},
   "source": [
    "## Multi-target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "55fca85e-b8bc-4365-a547-074cd1f61a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8130012690993347\n",
      "0.5451922080963347\n",
      "0.5416223995044857\n"
     ]
    }
   ],
   "source": [
    "multi_target_bunch = sklearn.datasets.load_linnerud()\n",
    "multi_target_datas = multi_target_bunch.get(\"data\")\n",
    "multi_target_targets = multi_target_bunch.get(\"target\")\n",
    "\n",
    "for target_index in range(multi_target_targets.shape[1]):\n",
    "    multi_target_target = multi_target_targets[:,target_index].reshape(multi_target_targets.shape[0], 1)\n",
    "    train_and_test(\n",
    "        inp=multi_target_datas,\n",
    "        out=multi_target_target,\n",
    "        train_percent=0.80,\n",
    "        ScalerType=MyScaler,\n",
    "        RegressorType=MyRegressor,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
