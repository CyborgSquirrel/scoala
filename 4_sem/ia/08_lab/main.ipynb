{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c983cdef-ba51-4524-b2c9-f60043fc7d8f",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55ef3bc5-cfad-4c2d-8507-e3ff496103ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import sklearn.linear_model\n",
    "import sklearn.preprocessing\n",
    "import sklearn.metrics\n",
    "import sklearn.datasets\n",
    "import numpy as np\n",
    "import dataclasses\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "import ipywidgets\n",
    "import typing\n",
    "import abc\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aef43775-950e-482b-8970-949b9a12c6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x: float):\n",
    "    return 1 / (1 + math.exp(-x))\n",
    "\n",
    "def rectified_linear(x: float):\n",
    "    if x <= 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2040016-7322-4e8e-b08e-e456b450d3e2",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f157380-aee7-4ab0-8fb3-441789e47e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_iris(path: str):\n",
    "    with open(path) as f:\n",
    "        reader = csv.reader(f)\n",
    "        \n",
    "        inp = []\n",
    "        out = []\n",
    "        for line in reader:\n",
    "            if len(line) == 0:\n",
    "                continue\n",
    "            \n",
    "            features_line = []\n",
    "            inp.append(features_line)\n",
    "            for i, value in enumerate(line):\n",
    "                if i < 4:\n",
    "                    value = float(value)\n",
    "                    features_line.append(value)\n",
    "                else:\n",
    "                    out.append(value)\n",
    "        \n",
    "        inp = np.array(inp)\n",
    "        out_name_to_number = {\n",
    "            \"Iris-setosa\": 0,\n",
    "            \"Iris-versicolor\": 1,\n",
    "            \"Iris-virginica\": 2,\n",
    "        }\n",
    "        out = np.array([ out_name_to_number[name] for name in out ])\n",
    "        \n",
    "        return inp, out\n",
    "\n",
    "data_inp_iris, data_out_iris = read_data_iris(\"data/iris.data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f68eceb0-8f97-4cea-9c21-2c14088933e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_breast_cancer(path: str):\n",
    "    with open(path) as f:\n",
    "        reader = csv.reader(f)\n",
    "        \n",
    "        inp = []\n",
    "        out = []\n",
    "        for line in reader:\n",
    "            if len(line) == 0:\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                features_line = []\n",
    "                for i, value in enumerate(line):\n",
    "                    if i < 10:\n",
    "                        value = float(value)\n",
    "                        features_line.append(value)\n",
    "                    else:\n",
    "                        if value == \"2\":\n",
    "                            out.append(0)\n",
    "                        elif value == \"4\":\n",
    "                            out.append(1)\n",
    "                        else:\n",
    "                            assert False\n",
    "                inp.append(features_line)\n",
    "            except ValueError:\n",
    "                pass\n",
    "        \n",
    "        inp = np.array(inp)\n",
    "        out = np.array(out)\n",
    "        \n",
    "        return inp, out\n",
    "\n",
    "data_inp_breast_cancer, data_out_breast_cancer = read_data_breast_cancer(\"data/breast-cancer.data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6003b9-20f9-4869-9162-42472906401b",
   "metadata": {},
   "source": [
    "# Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "97971de4-b865-440b-ab4e-d6bad9bce6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Regression(metaclass=abc.ABCMeta):\n",
    "    @abc.abstractmethod\n",
    "    def fit(self, inp: np.ndarray, out: np.ndarray):\n",
    "        pass\n",
    "    \n",
    "    @abc.abstractmethod\n",
    "    def predict(self, inp: np.ndarray) -> np.ndarray:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "bdecda8b-2a64-46be-bf74-c8414efdf0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(\n",
    "    inp: np.ndarray,\n",
    "    out: np.ndarray,\n",
    "    *,\n",
    "    k: int,\n",
    "    regressor: Regression,\n",
    "):\n",
    "    length = len(inp)\n",
    "\n",
    "    # shuffle data\n",
    "    indices = np.arange(length)\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    inp = inp[indices]\n",
    "    out = out[indices]\n",
    "    \n",
    "    accuracy_sum = 0\n",
    "    \n",
    "    negative_log_likelihood_loss = 0\n",
    "    for i in range(k):\n",
    "        negative_log_likelihood_loss_sum = 0\n",
    "    \n",
    "        # split into train and test\n",
    "        test_start_index = int((i  )/k * length)\n",
    "        test_stop_index =  int((i+1)/k * length)\n",
    "        \n",
    "        inp_test = inp[test_start_index:test_stop_index,:]\n",
    "        out_test = out[test_start_index:test_stop_index]\n",
    "        \n",
    "        inp_train = np.delete(inp, np.s_[test_start_index:test_stop_index], 0)\n",
    "        out_train = np.delete(out, np.s_[test_start_index:test_stop_index], 0)\n",
    "        \n",
    "        # normallize\n",
    "        scaler = sklearn.preprocessing.StandardScaler()\n",
    "        scaler.fit(inp_train)\n",
    "        inp_train = scaler.transform(inp_train)\n",
    "        inp_test = scaler.transform(inp_test)\n",
    "\n",
    "        # train\n",
    "        regressor.fit(inp_train, out_train)\n",
    "        \n",
    "        # test\n",
    "        predicted_test, full_predictions = regressor.predict(inp_test)\n",
    "        accuracy = sklearn.metrics.accuracy_score(out_test, predicted_test)\n",
    "        accuracy_sum += accuracy\n",
    "        \n",
    "        # negative log likelihood loss\n",
    "        for correct_class, prediction in zip(out_train, full_predictions):\n",
    "            for prediction_value in prediction:\n",
    "                if prediction_value[0] == correct_class:\n",
    "                    correct_prediction = prediction_value\n",
    "                    break\n",
    "            negative_log_likelihood_loss_sum -= (\n",
    "                math.log(correct_prediction[1])\n",
    "            )\n",
    "        negative_log_likelihood_loss += negative_log_likelihood_loss_sum\n",
    "    \n",
    "    accuracy = accuracy_sum / k\n",
    "    negative_log_likelihood_loss = negative_log_likelihood_loss / k\n",
    "    \n",
    "    print(accuracy)\n",
    "    print(negative_log_likelihood_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "13cb9631-049d-46f2-9aa4-7c4b146215de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_2d_shape(matrix: list[list[typing.Any]]) -> (int, int):\n",
    "    width = None\n",
    "    height = len(matrix)\n",
    "    for row in matrix:\n",
    "        if width is None:\n",
    "            width = len(row)\n",
    "        assert width == len(row)\n",
    "    return (width, height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a7dac7e4-9ae6-4038-b911-d0205ecd40e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EpochKind(metaclass=abc.ABCMeta):\n",
    "    pass\n",
    "\n",
    "class EpochKindStochastic(EpochKind):\n",
    "    pass\n",
    "\n",
    "class EpochKindBatch(EpochKind):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "99426492-d731-42bb-853c-0d8539f4bbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActivationFunctionKind(metaclass=abc.ABCMeta):\n",
    "    pass\n",
    "\n",
    "class ActivationFunctionKindSoftmax(ActivationFunctionKind):\n",
    "    pass\n",
    "\n",
    "@dataclasses.dataclass(kw_only=True)\n",
    "class ActivationFunctionKindSigmoid(ActivationFunctionKind):\n",
    "    threshold: typing.Optional[float] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "70f2aa13-055a-44a1-8d03-22a56b45cb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLogisticRegression(Regression):\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        epoch_kind: EpochKind,\n",
    "        activation_function_kind: ActivationFunctionKind,\n",
    "        learning_rate: float,\n",
    "        regularization_param: float,\n",
    "        generations_count: int,\n",
    "    ):\n",
    "        self.__learning_rate = learning_rate\n",
    "        self.__regularization_param = regularization_param\n",
    "        self.__generations_count = generations_count\n",
    "        self.__category_set = None\n",
    "        self.__w = None\n",
    "        self.__epoch_kind = epoch_kind\n",
    "        self.__activation_function_kind = activation_function_kind\n",
    "    \n",
    "    def __category_gradient(\n",
    "        self,\n",
    "        inp_values,\n",
    "        correct_category,\n",
    "        category,\n",
    "    ) -> float:\n",
    "        if type(self.__activation_function_kind) is ActivationFunctionKindSoftmax:\n",
    "            computed_out = (\n",
    "                math.exp(\n",
    "                    sum(\n",
    "                        w_value * inp_value\n",
    "                        for w_value, inp_value\n",
    "                        in zip(self.__w[category], [1] + inp_values)\n",
    "                    )\n",
    "                )\n",
    "                /\n",
    "                sum(\n",
    "                    math.exp(\n",
    "                        sum(\n",
    "                            w_value * inp_value\n",
    "                            for w_value, inp_value\n",
    "                            in zip(self.__w[category_2], [1] + inp_values)\n",
    "                        )\n",
    "                    )\n",
    "                    for category_2 in self.__category_set\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            err = (\n",
    "                float(category == correct_category)\n",
    "                -\n",
    "                computed_out\n",
    "            )\n",
    "            \n",
    "            return [\n",
    "                -1 * err * inp_value\n",
    "                +\n",
    "                -1 * self.__regularization_param * 2 * w_value\n",
    "                for inp_value, w_value in zip([1] + inp_values, self.__w[category])\n",
    "            ]\n",
    "        elif type(self.__activation_function_kind) is ActivationFunctionKindSigmoid:\n",
    "            computed_out = sigmoid(\n",
    "                sum(\n",
    "                    w_value * inp_value\n",
    "                    for w_value, inp_value\n",
    "                    in zip(self.__w[category], [1] + inp_values)\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            err = (\n",
    "                float(category == correct_category)\n",
    "                -\n",
    "                computed_out\n",
    "            )\n",
    "            \n",
    "            return [\n",
    "                err * computed_out * (1 - computed_out) * inp_value\n",
    "                for inp_value in [1] + inp_values\n",
    "            ]\n",
    "        else:\n",
    "            assert False\n",
    "    \n",
    "    def __category_computed(\n",
    "        self,\n",
    "        inp_values,\n",
    "        category,\n",
    "    ) -> float:\n",
    "        if type(self.__activation_function_kind) is ActivationFunctionKindSoftmax:\n",
    "            denominator = (\n",
    "                sum(\n",
    "                    math.exp(\n",
    "                        sum(\n",
    "                            w_value * inp_value\n",
    "                            for w_value, inp_value\n",
    "                            in zip(self.__w[category_2], [1] + inp_values)\n",
    "                        )\n",
    "                    )\n",
    "                    for category_2 in self.__category_set\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            numerator = (\n",
    "                math.exp(\n",
    "                    sum(\n",
    "                        w_value * inp_value\n",
    "                        for w_value, inp_value\n",
    "                        in zip(self.__w[category], [1] + inp_values)\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            computed = (\n",
    "                -math.log(numerator / denominator)\n",
    "                -\n",
    "                self.__regularization_param\n",
    "                *\n",
    "                sum(\n",
    "                    w_value**2\n",
    "                    for w_value in self.__w[category]\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            return computed\n",
    "        elif type(self.__activation_function_kind) is ActivationFunctionKindSigmoid:\n",
    "            return sigmoid(\n",
    "                sum(\n",
    "                    w_value * inp_value\n",
    "                    for w_value, inp_value\n",
    "                    in zip(self.__w[category], [1] + inp_values)\n",
    "                )\n",
    "            )\n",
    "        else:\n",
    "            assert False\n",
    "    \n",
    "    def fit(self, inp: np.ndarray, out: np.ndarray):\n",
    "        inp = inp.tolist()\n",
    "        out = out.tolist()\n",
    "        \n",
    "        self.__category_set = set(out)\n",
    "        \n",
    "        inp_shape = get_2d_shape(inp)\n",
    "        \n",
    "        self.__w = {\n",
    "            out_value: [\n",
    "                0 for _ in range(1 + inp_shape[0])\n",
    "            ]\n",
    "            for out_value in self.__category_set\n",
    "        }\n",
    "        \n",
    "        for generation_index in range(self.__generations_count):\n",
    "            if type(self.__epoch_kind) is EpochKindBatch:\n",
    "                batch_gradient_sum = {\n",
    "                    out_value_2: [\n",
    "                        0 for _ in range(1 + inp_shape[0])\n",
    "                    ]\n",
    "                    for out_value_2 in self.__category_set\n",
    "                }\n",
    "            \n",
    "            for inp_values, correct_category in zip(inp, out):\n",
    "                category_to_gradient = dict()\n",
    "                for category in self.__category_set:\n",
    "                    category_to_gradient[category] = self.__category_gradient(\n",
    "                        inp_values,\n",
    "                        correct_category,\n",
    "                        category,\n",
    "                    )\n",
    "                \n",
    "                if type(self.__epoch_kind) is EpochKindStochastic:\n",
    "                    for out_value_2 in self.__category_set:                \n",
    "                        for i in range(1 + inp_shape[0]):\n",
    "                            self.__w[out_value_2][i] += category_to_gradient[out_value_2][i] * self.__learning_rate\n",
    "                        \n",
    "                if type(self.__epoch_kind) is EpochKindBatch:\n",
    "                    for out_value_2 in self.__category_set:                \n",
    "                        for i in range(1 + inp_shape[0]):\n",
    "                            batch_gradient_sum[out_value_2][i] += category_to_gradient[out_value_2][i]\n",
    "            \n",
    "            if type(self.__epoch_kind) is EpochKindBatch:\n",
    "                for out_value_2 in self.__category_set:\n",
    "                    for i in range(1 + inp_shape[0]):\n",
    "                        self.__w[out_value_2][i] += batch_gradient_sum[out_value_2][i] / inp_shape[1] * self.__learning_rate\n",
    "    \n",
    "    def predict(self, inp: np.ndarray) -> np.ndarray:\n",
    "        inp = inp.tolist()\n",
    "        \n",
    "        full_predictions = []\n",
    "        predictions = []\n",
    "        for inp_values in inp:\n",
    "            possibilities = []\n",
    "            \n",
    "            use_threshold = (\n",
    "                type(self.__activation_function_kind) is ActivationFunctionKindSigmoid\n",
    "                and\n",
    "                self.__activation_function_kind.threshold is not None\n",
    "            )\n",
    "            \n",
    "            negative_log_likelihood_loss = 0\n",
    "            for category in self.__category_set:\n",
    "                computed_out = self.__category_computed(\n",
    "                    inp_values,\n",
    "                    category,\n",
    "                )\n",
    "                \n",
    "                if use_threshold:\n",
    "                    computed_out = float(\n",
    "                        computed_out > self.__activation_function_kind.threshold\n",
    "                    )\n",
    "                \n",
    "                possibilities.append((category, computed_out))\n",
    "            \n",
    "            full_predictions.append(possibilities)\n",
    "            \n",
    "            if use_threshold:\n",
    "                for possibility in possibilities:\n",
    "                    if possibility[1] == 1:\n",
    "                        best_possibility = possibility[0]\n",
    "            else:\n",
    "                best_possibility = max(possibilities, key=lambda a: a[1])[0]\n",
    "            \n",
    "            predictions.append(best_possibility)\n",
    "        predictions = np.array(predictions)\n",
    "        return predictions, full_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "736276a0-61fb-475e-9697-64ebd2c8219a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToolLogisticRegression(Regression):\n",
    "    def __init__(self):\n",
    "        self.__regressor = sklearn.linear_model.LogisticRegression()\n",
    "    \n",
    "    def fit(self, inp: np.ndarray, out: np.ndarray):\n",
    "        self.__regressor.fit(inp, out)\n",
    "    \n",
    "    def predict(self, inp: np.ndarray) -> np.ndarray:\n",
    "        return self.__regressor.predict(inp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8040bbd8-3f23-4447-8a4b-5d94360ca144",
   "metadata": {},
   "source": [
    "## Breast cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "a205f10a-410d-427c-8687-b2d72358662b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9691602728047741\n"
     ]
    }
   ],
   "source": [
    "cross_validate(\n",
    "    data_inp_breast_cancer,\n",
    "    data_out_breast_cancer,\n",
    "    k=10,\n",
    "    regressor=MyLogisticRegression(\n",
    "        epoch_kind=EpochKindStochastic(),\n",
    "        # epoch_kind=EpochKindBatch(),\n",
    "        activation_function_kind=ActivationFunctionKindSoftmax(),\n",
    "        learning_rate = 0.01,\n",
    "        regularization_param = 0.007,\n",
    "        generations_count = 1,\n",
    "    ),\n",
    "    # regressor=ToolLogisticRegression(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2400e523-c029-4ace-9966-20b96ee410a4",
   "metadata": {},
   "source": [
    "## Iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "37b9b059-709a-4365-b2da-372c4b382846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.82\n",
      "7.7564538843421875\n"
     ]
    }
   ],
   "source": [
    "cross_validate(\n",
    "    data_inp_iris,\n",
    "    data_out_iris,\n",
    "    k=10,\n",
    "    regressor=MyLogisticRegression(\n",
    "        epoch_kind=EpochKindStochastic(),\n",
    "        # epoch_kind=EpochKindBatch(),\n",
    "        # activation_function_kind=ActivationFunctionKindSoftmax(),\n",
    "        activation_function_kind=ActivationFunctionKindSigmoid(\n",
    "            # threshold=0.01\n",
    "        ),\n",
    "        learning_rate = 0.05,\n",
    "        regularization_param = 0.1,\n",
    "        generations_count = 5,\n",
    "    ),\n",
    "    # regressor=ToolLogisticRegression(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565cb68c-fde2-4896-8cfe-200105c895b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
