{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bfac1b1-970a-406d-bd5b-0fa0f637d740",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c862c41c-517a-4ae9-94c4-3b351ce5391d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:02:05.083544: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import typing\n",
    "import itertools\n",
    "import json\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import os.path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "import csv\n",
    "import ipywidgets\n",
    "from IPython.display import display\n",
    "import math\n",
    "import html\n",
    "import re\n",
    "import random\n",
    "\n",
    "import tensorflow.keras.utils as ku\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eae4462-52f1-4ca4-bba2-db6f1bea191b",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9631e12c-0552-4891-915b-d43061d02675",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "486c2856-dba5-48f7-9f7f-9e45a7d314dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>emotion</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>text_normalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3078803375</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-07-24 10:42:49+00:00</td>\n",
       "      <td>hopeless for tmr :(</td>\n",
       "      <td>hopeless for tmr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>383849833</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-07-24 10:42:48+00:00</td>\n",
       "      <td>Everything in the kids section of IKEA is so c...</td>\n",
       "      <td>everything in the kids section of ikea is so c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>486942332</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-07-24 10:42:48+00:00</td>\n",
       "      <td>@Hegelbon That heart sliding into the waste ba...</td>\n",
       "      <td>that heart sliding into the waste basket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>359645394</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-07-24 10:42:48+00:00</td>\n",
       "      <td>“@ketchBurning: I hate Japanese call him \"bani...</td>\n",
       "      <td>i hate japanese call him bani me too</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>490280208</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-07-24 10:42:47+00:00</td>\n",
       "      <td>Dang starting next week I have \"work\" :(</td>\n",
       "      <td>dang starting next week i have work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>2399336389</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-07-24 08:11:16+00:00</td>\n",
       "      <td>@chriswiggin3 Chris, that's great to hear :) D...</td>\n",
       "      <td>chris that s great to hear due times reminder...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>16451669</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-07-24 08:11:16+00:00</td>\n",
       "      <td>@RachelLiskeard Thanks for the shout-out :) It...</td>\n",
       "      <td>thanks for the shout out it s great to have y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>2528349649</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-07-24 08:11:16+00:00</td>\n",
       "      <td>@side556 Hey!  :)  Long time no talk...</td>\n",
       "      <td>hey long time no talk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>3065747142</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-07-24 08:11:16+00:00</td>\n",
       "      <td>@staybubbly69 as Matt would say. WELCOME TO AD...</td>\n",
       "      <td>as matt would say welcome to adulthood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>67752342</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-07-24 08:11:16+00:00</td>\n",
       "      <td>@DanielOConnel18 you could say he will have eg...</td>\n",
       "      <td>you could say he will have egg on his face</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            user  emotion                created_at  \\\n",
       "0     3078803375        0 2015-07-24 10:42:49+00:00   \n",
       "1      383849833        0 2015-07-24 10:42:48+00:00   \n",
       "2      486942332        0 2015-07-24 10:42:48+00:00   \n",
       "3      359645394        0 2015-07-24 10:42:48+00:00   \n",
       "4      490280208        0 2015-07-24 10:42:47+00:00   \n",
       "...          ...      ...                       ...   \n",
       "9995  2399336389        1 2015-07-24 08:11:16+00:00   \n",
       "9996    16451669        1 2015-07-24 08:11:16+00:00   \n",
       "9997  2528349649        1 2015-07-24 08:11:16+00:00   \n",
       "9998  3065747142        1 2015-07-24 08:11:16+00:00   \n",
       "9999    67752342        1 2015-07-24 08:11:16+00:00   \n",
       "\n",
       "                                                   text  \\\n",
       "0                                   hopeless for tmr :(   \n",
       "1     Everything in the kids section of IKEA is so c...   \n",
       "2     @Hegelbon That heart sliding into the waste ba...   \n",
       "3     “@ketchBurning: I hate Japanese call him \"bani...   \n",
       "4              Dang starting next week I have \"work\" :(   \n",
       "...                                                 ...   \n",
       "9995  @chriswiggin3 Chris, that's great to hear :) D...   \n",
       "9996  @RachelLiskeard Thanks for the shout-out :) It...   \n",
       "9997            @side556 Hey!  :)  Long time no talk...   \n",
       "9998  @staybubbly69 as Matt would say. WELCOME TO AD...   \n",
       "9999  @DanielOConnel18 you could say he will have eg...   \n",
       "\n",
       "                                        text_normalized  \n",
       "0                                     hopeless for tmr   \n",
       "1     everything in the kids section of ikea is so c...  \n",
       "2             that heart sliding into the waste basket   \n",
       "3                  i hate japanese call him bani me too  \n",
       "4                  dang starting next week i have work   \n",
       "...                                                 ...  \n",
       "9995   chris that s great to hear due times reminder...  \n",
       "9996   thanks for the shout out it s great to have y...  \n",
       "9997                             hey long time no talk   \n",
       "9998            as matt would say welcome to adulthood   \n",
       "9999        you could say he will have egg on his face   \n",
       "\n",
       "[10000 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_json = pd.read_json(\"./data/positive.json\")\n",
    "negative_json = pd.read_json(\"./data/negative.json\")\n",
    "\n",
    "data_twitter = pd.concat(\n",
    "    [\n",
    "        negative_json.assign(emotion=0),\n",
    "        positive_json.assign(emotion=1),\n",
    "    ],\n",
    "    ignore_index=True,\n",
    ")\n",
    "\n",
    "data_twitter = data_twitter[[\"user\", \"emotion\", \"created_at\", \"text\"]]\n",
    "data_twitter[\"user\"] = data_twitter[\"user\"].map(lambda a: a[\"id\"])\n",
    "\n",
    "RE_TWITTER_USERNAME = re.compile(\"@[A-Za-z0-9_]{,15}\")\n",
    "RE_TWITTER_URL = re.compile(\"https?://t[.]co/[A-Za-z0-9]{10}\")\n",
    "\n",
    "text_normalized = (\n",
    "    data_twitter[\"text\"]\n",
    "        .map(lambda a: html.unescape(a))\n",
    "        .replace(RE_TWITTER_USERNAME, \" \")\n",
    "        .replace(RE_TWITTER_URL, \" \")\n",
    "        .replace(re.compile(\"\\\\s\"), \" \")\n",
    "        .replace(re.compile(\"[^A-Za-z0-9 ]\"), \" \")\n",
    "        .map(lambda a: a.lower())\n",
    "        .replace(re.compile(\"\\\\s+\"), \" \")\n",
    "        .rename(\"text_normalized\")\n",
    ")\n",
    "\n",
    "data_twitter = pd.concat(\n",
    "    [\n",
    "        data_twitter,\n",
    "        text_normalized,\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "data_twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de167f43-ad5f-434c-a9e1-62cf45cb5beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = \" \".join(data_twitter[\"text_normalized\"]).split()\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41b0a254-a352-4971-b34c-6c8b0d9e372c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>size</th>\n",
       "      <th>emo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3846</th>\n",
       "      <td>569749124</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4076</th>\n",
       "      <td>618850249</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8299</th>\n",
       "      <td>3242573418</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4539</th>\n",
       "      <td>898630568</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4046</th>\n",
       "      <td>613416758</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>19970375</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8072</th>\n",
       "      <td>3179744365</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8068</th>\n",
       "      <td>3179220806</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4448</th>\n",
       "      <td>843288175</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8053</th>\n",
       "      <td>3170716296</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>15625348</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3679</th>\n",
       "      <td>532135503</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6701</th>\n",
       "      <td>2528451843</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7116</th>\n",
       "      <td>2790993826</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5153</th>\n",
       "      <td>1334920309</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7060</th>\n",
       "      <td>2761192037</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6290</th>\n",
       "      <td>2343084459</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2611</th>\n",
       "      <td>311333317</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2614</th>\n",
       "      <td>313306238</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5701</th>\n",
       "      <td>1704437790</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5799</th>\n",
       "      <td>1893327535</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5279</th>\n",
       "      <td>1412892476</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806</th>\n",
       "      <td>48201591</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3395</th>\n",
       "      <td>459518585</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4922</th>\n",
       "      <td>1161735547</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4749</th>\n",
       "      <td>1037183916</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>43309017</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>42171714</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1056</th>\n",
       "      <td>75272978</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5090</th>\n",
       "      <td>1289045496</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3141</th>\n",
       "      <td>403522137</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2978</th>\n",
       "      <td>376091214</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6000</th>\n",
       "      <td>2207348437</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4607</th>\n",
       "      <td>945830622</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2991</th>\n",
       "      <td>378623571</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5520</th>\n",
       "      <td>1583109553</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8265</th>\n",
       "      <td>3239904114</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2837</th>\n",
       "      <td>350507190</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2604</th>\n",
       "      <td>309719291</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8282</th>\n",
       "      <td>3241352324</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8475</th>\n",
       "      <td>3313525485</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7634</th>\n",
       "      <td>2993128488</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2901</th>\n",
       "      <td>361268597</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8546</th>\n",
       "      <td>3351305314</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1620</th>\n",
       "      <td>148771975</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5349</th>\n",
       "      <td>1463512856</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8281</th>\n",
       "      <td>3241349858</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            user  size  emo\n",
       "3846   569749124     2    1\n",
       "4076   618850249     2    1\n",
       "8299  3242573418     2    1\n",
       "4539   898630568     2    1\n",
       "4046   613416758     2    1\n",
       "264     19970375     2    1\n",
       "8072  3179744365     2    1\n",
       "8068  3179220806     2    1\n",
       "4448   843288175     2    1\n",
       "8053  3170716296     2    1\n",
       "125     15625348     2    1\n",
       "3679   532135503     2    1\n",
       "6701  2528451843     2    1\n",
       "7116  2790993826     2    1\n",
       "5153  1334920309     2    1\n",
       "7060  2761192037     2    1\n",
       "6290  2343084459     2    1\n",
       "2611   311333317     2    1\n",
       "2614   313306238     2    1\n",
       "5701  1704437790     2    1\n",
       "5799  1893327535     2    1\n",
       "5279  1412892476     2    1\n",
       "806     48201591     2    1\n",
       "3395   459518585     2    1\n",
       "4922  1161735547     2    1\n",
       "4749  1037183916     2    1\n",
       "730     43309017     2    1\n",
       "711     42171714     2    1\n",
       "1056    75272978     2    1\n",
       "5090  1289045496     2    1\n",
       "3141   403522137     3    1\n",
       "2978   376091214     3    1\n",
       "6000  2207348437     3    2\n",
       "4607   945830622     3    2\n",
       "2991   378623571     3    2\n",
       "5520  1583109553     3    2\n",
       "8265  3239904114     3    1\n",
       "2837   350507190     3    2\n",
       "2604   309719291     3    2\n",
       "8282  3241352324     4    2\n",
       "8475  3313525485     4    3\n",
       "7634  2993128488     5    4\n",
       "2901   361268597     5    3\n",
       "8546  3351305314     6    2\n",
       "1620   148771975     6    5\n",
       "5349  1463512856     6    2\n",
       "8281  3241349858     7    3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = data_twitter.groupby(\"user\", as_index=False).agg(\n",
    "    size=pd.NamedAgg(column=\"emotion\", aggfunc=\"size\"),\n",
    "    emo=pd.NamedAgg(column=\"emotion\", aggfunc=\"sum\"),\n",
    ").sort_values(\"size\")\n",
    "\n",
    "a[(a[\"emo\"] > 0) & (a[\"size\"] - a[\"emo\"] > 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28254886-9051-4b18-86ad-a6d7946d2a42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>emotion</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>text_normalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1089</th>\n",
       "      <td>1463512856</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-07-24 10:31:16+00:00</td>\n",
       "      <td>5SOS Calum5SOS Luke5SOS Ashton5SOS I bet $20 t...</td>\n",
       "      <td>5sos calum5sos luke5sos ashton5sos i bet 20 to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1159</th>\n",
       "      <td>1463512856</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-07-24 10:30:37+00:00</td>\n",
       "      <td>James_Yammouni I bet $20 that you will follow ...</td>\n",
       "      <td>james yammouni i bet 20 that you will follow c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2659</th>\n",
       "      <td>1463512856</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-07-24 10:15:33+00:00</td>\n",
       "      <td>ladygaga I bet $20 to a friend that you will f...</td>\n",
       "      <td>ladygaga i bet 20 to a friend that you will fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2682</th>\n",
       "      <td>1463512856</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-07-24 10:15:21+00:00</td>\n",
       "      <td>justinbieber I bet $20 to a friend that you wi...</td>\n",
       "      <td>justinbieber i bet 20 to a friend that you wil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8032</th>\n",
       "      <td>1463512856</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-07-24 08:16:10+00:00</td>\n",
       "      <td>5SOS Calum5SOS Luke5SOS Ashton5SOS Hey guys! P...</td>\n",
       "      <td>5sos calum5sos luke5sos ashton5sos hey guys pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8104</th>\n",
       "      <td>1463512856</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-07-24 08:15:59+00:00</td>\n",
       "      <td>James_Yammouni Hey JAMES! Thanks for the follo...</td>\n",
       "      <td>james yammouni hey james thanks for the follow...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            user  emotion                created_at  \\\n",
       "1089  1463512856        0 2015-07-24 10:31:16+00:00   \n",
       "1159  1463512856        0 2015-07-24 10:30:37+00:00   \n",
       "2659  1463512856        0 2015-07-24 10:15:33+00:00   \n",
       "2682  1463512856        0 2015-07-24 10:15:21+00:00   \n",
       "8032  1463512856        1 2015-07-24 08:16:10+00:00   \n",
       "8104  1463512856        1 2015-07-24 08:15:59+00:00   \n",
       "\n",
       "                                                   text  \\\n",
       "1089  5SOS Calum5SOS Luke5SOS Ashton5SOS I bet $20 t...   \n",
       "1159  James_Yammouni I bet $20 that you will follow ...   \n",
       "2659  ladygaga I bet $20 to a friend that you will f...   \n",
       "2682  justinbieber I bet $20 to a friend that you wi...   \n",
       "8032  5SOS Calum5SOS Luke5SOS Ashton5SOS Hey guys! P...   \n",
       "8104  James_Yammouni Hey JAMES! Thanks for the follo...   \n",
       "\n",
       "                                        text_normalized  \n",
       "1089  5sos calum5sos luke5sos ashton5sos i bet 20 to...  \n",
       "1159  james yammouni i bet 20 that you will follow c...  \n",
       "2659  ladygaga i bet 20 to a friend that you will fo...  \n",
       "2682  justinbieber i bet 20 to a friend that you wil...  \n",
       "8032  5sos calum5sos luke5sos ashton5sos hey guys pl...  \n",
       "8104  james yammouni hey james thanks for the follow...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_twitter.groupby(\"user\", as_index=False).get_group(1463512856)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5cf381c-bd51-4a2a-ba97-badeb71d3574",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPECIAL_TOKEN = {\n",
    "    \"NULL\": 0,\n",
    "    \"UNKNOWN\": 1,\n",
    "    \"BEGIN\": 2,\n",
    "    \"POSITIVE\": 3,\n",
    "    \"NEGATIVE\": 4,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "158d9dc9-9c46-4bb9-8cb4-0b78f8a9473f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_len = len(SPECIAL_TOKEN) + len(tokenizer.word_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d4eda82-53e4-4a26-b77f-4bd8d8d8aa51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user\n",
       "28513                               [2, 3, 6, 199, 11, 42, 163]\n",
       "75493                        [2, 3, 5, 60, 10225, 1259, 17, 54]\n",
       "634553        [2, 3, 111, 25, 42, 98, 1001, 1052, 54, 7, 88,...\n",
       "666743        [2, 4, 132, 64, 5, 299, 7, 7546, 5, 527, 18, 2...\n",
       "675253        [2, 3, 4170, 9, 83, 680, 1105, 8622, 8, 8623, ...\n",
       "                                    ...                        \n",
       "3388656496         [2, 4, 5, 141, 5, 129, 8, 395, 7, 1248, 110]\n",
       "3389146985                                          [2, 4, 165]\n",
       "3389164456                                   [2, 3, 779, 59, 6]\n",
       "3390537291              [2, 3, 402, 23, 17, 104, 4403, 79, 107]\n",
       "3390756107    [2, 4, 6261, 1731, 135, 7, 6262, 6263, 6264, 1...\n",
       "Length: 8559, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_twitter_tokenized = (\n",
    "    data_twitter\n",
    "        .groupby(\"user\", as_index=True)\n",
    "        .apply(lambda group:\n",
    "               list(itertools.chain.from_iterable(\n",
    "                   (\n",
    "                         [SPECIAL_TOKEN[\"BEGIN\"], SPECIAL_TOKEN[\"POSITIVE\"] if emotion == 1 else SPECIAL_TOKEN[\"NEGATIVE\"]]\n",
    "                       + [word-1+len(SPECIAL_TOKEN) for word in sequence]\n",
    "                       for sequence, emotion, _\n",
    "                       in zip(\n",
    "                           tokenizer.texts_to_sequences(group[\"text_normalized\"]),\n",
    "                           group[\"emotion\"],\n",
    "                           range(4),\n",
    "                       )\n",
    "                    )\n",
    "               ))\n",
    "        )\n",
    ")\n",
    "\n",
    "data_twitter_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9f32462-3647-40c5-9946-122e226d3a0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_sequence_len = data_twitter_tokenized.map(lambda a: len(a)).max()\n",
    "max_sequence_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d02373ca-8441-4284-bdac-9eed1f353494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n"
     ]
    }
   ],
   "source": [
    "max_sequence_len = 4\n",
    "ngrams = []\n",
    "for text in data_twitter_tokenized:\n",
    "    if len(text) < max_sequence_len:\n",
    "        ngrams.append(text + [SPECIAL_TOKEN[\"NULL\"]] * (max_sequence_len - len(text)))\n",
    "    else:\n",
    "        for i in range(len(text) - max_sequence_len + 1):\n",
    "            ngrams.append(text[i:i+max_sequence_len])\n",
    "\n",
    "ngrams = np.array(ngrams, dtype=int)\n",
    "\n",
    "data_in = ngrams[:,:max_sequence_len-1]\n",
    "data_out = ngrams[:,max_sequence_len-1]\n",
    "label = ku.to_categorical(data_out, num_classes=tokens_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1621383b-2cbf-4116-b1a5-772727583940",
   "metadata": {},
   "source": [
    "# Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da4da1d-0d18-41ba-ad5d-e39f657124d2",
   "metadata": {},
   "source": [
    "## Algo1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a65903-f3af-44aa-a7c1-7eca73de3546",
   "metadata": {},
   "source": [
    "Plan:\n",
    "\n",
    "Encode the text as follows:\n",
    "\n",
    "`begin_text` `text_emotion` `tokenized_words` `end_text`\n",
    "\n",
    "The model will predict the next token.\n",
    "\n",
    "You take its prediction, only look at the probabilities of the emotion signifiers, and return the likeliest one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "13e52b00-51a6-4492-9fd6-f92bf550f7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "TWITTER_CHECKPOINT_PATH = \"./model_2/cp.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ab657021-0b17-4b0d-8c2a-64b8712ac420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_6 (Embedding)     (None, 3, 100)            1207200   \n",
      "                                                                 \n",
      " bidirectional_6 (Bidirectio  (None, 3, 300)           301200    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 3, 300)            0         \n",
      "                                                                 \n",
      " lstm_13 (LSTM)              (None, 100)               160400    \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 603)               60903     \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 12072)             7291488   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,021,191\n",
      "Trainable params: 9,021,191\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "Unsuccessful TensorSliceReader constructor: Failed to find any matching files for ./model_2/cp.ckpt",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "Input \u001b[0;32mIn [54]\u001b[0m, in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     12\u001b[0m               optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(model\u001b[38;5;241m.\u001b[39msummary())\n\u001b[0;32m---> 15\u001b[0m model\u001b[38;5;241m.\u001b[39mload_weights(TWITTER_CHECKPOINT_PATH)\n",
      "File \u001b[0;32m/nix/store/gry2d409icyrskf2mnx1v2rdr1hbaqxy-python3-3.10.8-env/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/nix/store/gry2d409icyrskf2mnx1v2rdr1hbaqxy-python3-3.10.8-env/lib/python3.10/site-packages/tensorflow/python/training/py_checkpoint_reader.py:31\u001b[0m, in \u001b[0;36merror_translator\u001b[0;34m(e)\u001b[0m\n\u001b[1;32m     27\u001b[0m error_message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnot found in checkpoint\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m error_message \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFailed to find any \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatching files for\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01min\u001b[39;00m error_message:\n\u001b[0;32m---> 31\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m errors_impl\u001b[38;5;241m.\u001b[39mNotFoundError(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, error_message)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSliced checkpoints are not supported\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m error_message \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mData type \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnot \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupported\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01min\u001b[39;00m error_message:\n\u001b[1;32m     36\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m errors_impl\u001b[38;5;241m.\u001b[39mUnimplementedError(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, error_message)\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for ./model_2/cp.ckpt"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(tokens_len, 100,\n",
    "                    input_length=max_sequence_len-1))\n",
    "model.add(Bidirectional(LSTM(150, return_sequences=True)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(tokens_len/20, activation='relu',\n",
    "                kernel_regularizer=regularizers.l2(0.01)))\n",
    "# model.add(Dense(tokens_len/20, activation='relu'))\n",
    "model.add(Dense(tokens_len, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "model.load_weights(TWITTER_CHECKPOINT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "65b127ac-7b6f-411d-97c6-b67c2556c2f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1188/2777 [===========>..................] - ETA: 1:33 - loss: 7.1836 - accuracy: 0.0293"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [55]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m cp_callback \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mModelCheckpoint(\n\u001b[1;32m      2\u001b[0m     filepath\u001b[38;5;241m=\u001b[39mTWITTER_CHECKPOINT_PATH,\n\u001b[1;32m      3\u001b[0m     save_weights_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      4\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m      5\u001b[0m )\n\u001b[0;32m----> 7\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m      8\u001b[0m     data_in,\n\u001b[1;32m      9\u001b[0m     label,\n\u001b[1;32m     10\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m     11\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     12\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[cp_callback],\n\u001b[1;32m     13\u001b[0m )\n",
      "File \u001b[0;32m/nix/store/gry2d409icyrskf2mnx1v2rdr1hbaqxy-python3-3.10.8-env/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/nix/store/gry2d409icyrskf2mnx1v2rdr1hbaqxy-python3-3.10.8-env/lib/python3.10/site-packages/keras/engine/training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1562\u001b[0m ):\n\u001b[1;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/nix/store/gry2d409icyrskf2mnx1v2rdr1hbaqxy-python3-3.10.8-env/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/nix/store/gry2d409icyrskf2mnx1v2rdr1hbaqxy-python3-3.10.8-env/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/nix/store/gry2d409icyrskf2mnx1v2rdr1hbaqxy-python3-3.10.8-env/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/nix/store/gry2d409icyrskf2mnx1v2rdr1hbaqxy-python3-3.10.8-env/lib/python3.10/site-packages/tensorflow/python/eager/function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2494\u001b[0m   (graph_function,\n\u001b[1;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/nix/store/gry2d409icyrskf2mnx1v2rdr1hbaqxy-python3-3.10.8-env/lib/python3.10/site-packages/tensorflow/python/eager/function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1865\u001b[0m     args,\n\u001b[1;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1867\u001b[0m     executing_eagerly)\n\u001b[1;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/nix/store/gry2d409icyrskf2mnx1v2rdr1hbaqxy-python3-3.10.8-env/lib/python3.10/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m/nix/store/gry2d409icyrskf2mnx1v2rdr1hbaqxy-python3-3.10.8-env/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cp_callback = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=TWITTER_CHECKPOINT_PATH,\n",
    "    save_weights_only=True,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    data_in,\n",
    "    label,\n",
    "    epochs=2,\n",
    "    verbose=1,\n",
    "    callbacks=[cp_callback],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b26638-057f-4931-84c9-59c89f88c376",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenizer.index_word[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e7a10150-0289-4626-8f56-c8629c861a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 33ms/step\n",
      "NEGATIVE\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "NEGATIVE\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "i   i   i   i   i   i   i   i   i\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "i   i   i   i   i   i   i   i   i\n"
     ]
    }
   ],
   "source": [
    "def twitter_predict(normalized_sentences: list[str], emotions: list[str], token_count) -> list[int]:\n",
    "    texts = [sentence.split() for sentence in normalized_sentences]\n",
    "    sequences = [\n",
    "        [word-1+len(SPECIAL_TOKEN) for word in sequence]\n",
    "        for sequence in tokenizer.texts_to_sequences(texts)\n",
    "    ]\n",
    "    data_in = []\n",
    "    for sequence, emotion in zip(sequences, emotions):\n",
    "        data_in += [SPECIAL_TOKEN[\"BEGIN\"]]\n",
    "        data_in += [SPECIAL_TOKEN[emotion]]\n",
    "        data_in += sequence\n",
    "    data_in += [SPECIAL_TOKEN[\"BEGIN\"]]\n",
    "    \n",
    "    tokens_index = len(data_in)\n",
    "    for token_index in range(token_count):\n",
    "        data_in_array = np.full((1, max_sequence_len), SPECIAL_TOKEN[\"NULL\"])\n",
    "        data_in_array[0,:len(data_in)] = data_in\n",
    "        prediction = model.predict(data_in_array)[0]\n",
    "        \n",
    "        if token_index == 0:\n",
    "            token = None\n",
    "            for i in [SPECIAL_TOKEN[\"POSITIVE\"], SPECIAL_TOKEN[\"NEGATIVE\"]]:\n",
    "                if token is None or prediction[i] > prediction[token]:\n",
    "                    token = i\n",
    "        else:\n",
    "            token = None\n",
    "            for i in range(len(prediction)):\n",
    "                if i in {SPECIAL_TOKEN[\"BEGIN\"], SPECIAL_TOKEN[\"POSITIVE\"], SPECIAL_TOKEN[\"NEGATIVE\"], SPECIAL_TOKEN[\"NULL\"], SPECIAL_TOKEN[\"UNKNOWN\"]}:\n",
    "                    continue\n",
    "\n",
    "                if token is None or prediction[i] > prediction[token]:\n",
    "                    token = i\n",
    "        \n",
    "        data_in.append(token)\n",
    "    return data_in[tokens_index:]\n",
    "            \n",
    "    \n",
    "def twitter_predict_emotion(normalized_sentences: list[str], emotions: list[str]) -> str:\n",
    "    tokens = twitter_predict(normalized_sentences, emotions, 1)\n",
    "    \n",
    "    if tokens[0] == SPECIAL_TOKEN[\"POSITIVE\"]:\n",
    "        return \"POSITIVE\"\n",
    "    elif tokens[0] == SPECIAL_TOKEN[\"NEGATIVE\"]:\n",
    "        return \"NEGATIVE\"\n",
    "    else:\n",
    "        assert False\n",
    "\n",
    "\n",
    "def twitter_predict_text(normalized_sentences: list[str], emotions: list[str], words: int) -> str:\n",
    "    tokens = twitter_predict(normalized_sentences, emotions, words)\n",
    "    tokens = [token+1-len(SPECIAL_TOKEN) for token in tokens]\n",
    "    text = tokenizer.sequences_to_texts([tokens])[0]\n",
    "    return \" \".join(text)\n",
    "\n",
    "\n",
    "print(twitter_predict_emotion(\n",
    "    [\"hopeless for tmr\", \"shame i m nearly 19\"],\n",
    "    [\"NEGATIVE\", \"NEGATIVE\"],\n",
    "))\n",
    "\n",
    "print(twitter_predict_emotion(\n",
    "    [\"for being top engaged members in my community this week\", \"hey james many thanks\"],\n",
    "    [\"POSITIVE\", \"POSITIVE\"],\n",
    "))\n",
    "\n",
    "print(twitter_predict_text(\n",
    "    [\"hopeless for tmr\", \"shame i m nearly 19\"],\n",
    "    [\"NEGATIVE\", \"NEGATIVE\"],\n",
    "    10,\n",
    "))\n",
    "\n",
    "print(twitter_predict_text(\n",
    "    [\"for being top engaged members in my community this week\", \"hey james many thanks\"],\n",
    "    [\"POSITIVE\", \"POSITIVE\"],\n",
    "    10,\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2765af2-f221-4f03-9254-1e62273d32da",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenizer.texts_to_sequences([[\"i\"]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0910bc09-3ca2-4c92-9595-b6d86ee73822",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
